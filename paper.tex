\documentclass{vldb}

%%% Packages
\usepackage{graphicx}
\usepackage{balance}
\usepackage{tikz}
\usepackage{standalone}
\usepackage{subfigure}

%%% TikZ libraries
\usetikzlibrary{backgrounds, positioning, decorations.pathreplacing, calc, fit}
\usetikzlibrary{shapes}

%%% Macros
\newcommand{\tbr}{\textbf{[TO BE REVISED]}}
\newcommand{\tbd}{\textbf{[TO BE DONE]}}

\begin{document}

% Title
\title{A Survey on Ordered Binary Decision Diagrams}

% Author(s)
\numberofauthors{1}

\author{
\alignauthor
	Daniel Kocher\\
    \affaddr{University of Salzburg}\\
    \email{Daniel.Kocher@stud.sbg.ac.at}
}

\maketitle

\begin{abstract}
This paper serves as a survey on \textit{ordered binary Decision diagrams}
(\textit{OBDDs}). It provides an overview of the representation of OBDDs, the
operations which can be applied efficiently, some aspects when implementing them
as well as their limitations and how to probably overcome them by using
alternative representations. No new results or insights are provided. \tbr
\end{abstract}

\section{Introduction}
\label{sec:introduction}

In computer-aided design (CAD) as well as other domains like artificial
intelligence or combinatorics, many problems can be formulated as Boolean
functions. These Boolean functions then can be represented symbolically using the
\textit{Binary Decision Diagrams} (\textit{BDDs}) introduced by Lee\cite{LEE59}
and Akers\cite{AKERS78} in 1959 and 1978, respectively.

In 1986 Bryant\cite{BRYANT86} published a paper of high impact, describing a
\textit{reduced} and \textit{ordered} class of BDDs, so-called \textit{ROBDDs}
(\textit{Reduced Ordered} BDDs) but in literature mostly referred to as
\textit{OBDDs}. OBDDs represent Boolean functions in a \textit{canonical}
form. This results in a compact form and very efficient tests for some properties,
e.g. satisfiability or equivalence\cite{BRYANT86}.

Bryant also introduced and experimentally evaluated efficient implementation
techniques for OBDDs in collaboration with Brace and
Rudell~\cite{BRACE90, BRYANT92}.

Already in the inital paper describing OBDDs, the importance of the variable
ordering was highlighted. Only if the variable ordering is chosen properly, it
will result in a small graph (OBDD) and, in turn, in more efficient testing.

Nonetheless representing Boolean functions using OBDDs has some drawbacks. Classes
of Boolean functions exist for which the size of the graph grows exponentially
independent of the variable ordering, e.g. integer
multiplication~\cite{BRYANT86, BRYANT91, WOELFEL01}.

These limitations of OBDDs motivated researchers to introduce heuristics and
other techniques like \textit{dynamic variable ordering}~\cite{RUDELL93} to solve
the problem of variable ordering~\cite{BOLLIG96}. Furthermore, alternative
representations which e.g. relax the ordering~\cite{BRYANT95} or change the
interpretation of nodes~\cite{BRYANT95, ANDERSEN97} were developed. Such
representations may be beneficial for some classes of Boolean functions but mostly
suffer from losing the canonical form and hence the desirable properties OBDDs
are famous for.

This paper serves as survey on symbolic Boolean function manipulation using OBDDs.
The following section describes the representation of Boolean functions through
BDDs as well as OBDDs. It also highlights the advantages and disadvantages of the
OBDD representation. The third section describes operations which can be applied
to OBDDs efficiently. No source code is provided but those can be looked up in
the corresponding papers easily (references are provided for each algorithm).
Section~\ref{sec:implementational-aspects} describes aspects one has to take into
account when implementing an OBDD package, such as what data structures to use
or how to deal with the problem of variable ordering. Limitations of the OBDD
representation are described in the subsequent section. The last section
discusses alternative representations to possibly overcome the limitations of
the OBDD representation. \tbr

\section{Representation Basics}
\label{sec:representation-basics}

\textit{Binary decision diagrams} (\textit{BDDs}) have been well studied since
Lee~\cite{LEE59} and especially Akers~\cite{AKERS78} introduced them. BDDs
represent a Boolean function $f$ as an acyclic, directed graph (DAG). The function
arguments may be omitted in some cases to keep the formulas simple, i.e. $f$
denotes $f(x_1, \ldots, x_2)$. Nodes represent variables and have one incoming
and two outgoing edges, each of which denotes the variable evaluates to 0 (left)
or 1 (right), respectively. Whenever the result of $f$ is fixed, an edge points
to one of the constant functions \textbf{0} or \textbf{1}. To evaluate $f$ for a
given variable assignment, one just follows the path for the respective variable
values. As soon as the path ends up in a constant, i.e. \textbf{0} or \textbf{1},
this is the result of the corresponding variable assignment. Akers~\cite{AKERS78}
already provided some techniques to simplify the BDD representation such as
combining equivalent nodes.

Figure~\ref{subfig:bdd} shows an example of a BDD representing the Boolean function
$f=(A \land B) \lor (B \land C)$. To simplify the graphs, the diagram style of
Bryant~\cite{BRYANT92} is reused, i.e. edge labels are skipped. Instead dashed
and solid lines are used to represent the value of the decision variable to be 0
and 1, respectively. This diagram style is used throughout this paper.

\begin{figure}[ht]
    \centering
    \subfigure[BDD]{
        \includestandalone[height = 3cm]{figs/bdd}
        \label{subfig:bdd}
    }
    \hskip1cm
    \subfigure[OBDD]{
        \includestandalone[height = 3cm]{figs/obdd}
        \label{subfig:obdd}
    }
    \caption{BDD and OBDD of $f=(A \land B) \lor (B \land C)$.}
    \label{fig:bdd-and-obdd}
\end{figure}

However, Bryant~\cite{BRYANT86} introduced some restrictions concerning the
ordering of the so-called \textit{decision variables} represented by the nodes
of the BDD. Furthermore, Bryant\cite{BRYANT86} was able to derive a reduced
representation of BDDs providing the DAG in a canonical form: the
\textit{Reduced Ordered Binary Decision Diagram} (\textit{ROBDD}; mostly referred
to as \textit{OBDD}, even by Bryant himself). In this paper, the terms ROBDD and
OBDD are used synonymously.

Figure~\ref{subfig:obdd} shows one possible ROBDD representation of
$f$. The following section covers the details of how
to derive the OBDD representation from a BDD. \tbr

\subsection{From BDDs to OBDDs}
\label{subsec:from-bdds-to-obdds}

As the name suggests, \textit{Reduced} Ordered Binary Decision Diagrams are a 
minimized representation of BDDs. Furthermore, the decision variables are ordered
consistently. More formally, for any node $n$ and their respective children $m_1$
and $m_2$, a total ordering is imposed, i.e. $var(n) < var(m_1)$ and
$var(n) < var(m_2)$, respectively, where $var(x)$ denotes the label of node
$x$~\cite{BRYANT86, BRYANT92}.

This \textit{variable ordering} affects the efficiency of the symbolic
manipulation because different variable orderings, in general, produce different
OBDDs. In the worst case, this will result in exponential complexity for bad
orderings. Nevertheless, as will be described in Section~\ref{sec:limitations},
there exist classes of functions for which the OBDD complexity is exponential
regardless of which variable ordering is chosen.

Before discussing the reduction procedure, some definitions are necessary. Here
the original definitions of Bryant~\cite{BRYANT86, BRYANT91} are reused.

A Boolean function can be represented as an OBDD, i.e. a rooted, directed,
acyclic graph (DAG) with a set of nodes $V$ as well as a set of edges $E$. 

There exist \textit{nonterminal} and \textit{terminal} nodes. Each
\textit{nonterminal} node $n$ has its own label $var(n)$ as well as two edges,
connecting it to its left $lo(n)\in V$ and right child $hi(n)\in V$, respectively. 
Each \textit{terminal} node $t$ has a unique value $value(t)$, i.e. $value(t)$
is a constant function (for Boolean functions \textbf{0} or \textbf{1}). Hence,
for each constant function only a single terminal node exists.

The following property has to hold for any nonterminal node $n$ in order to
satisfy the ordering requirement of an OBDD:
$var(n) < var(lo(n)) \land var(n) < var(hi(n))$.
In other words, for any path starting at the root of an OBDD, if a path is
followed until a terminal node is reached, the nonterminal nodes are traversed
strictly in the variable ordering.

\paragraph*{Reduction procedure}
\mbox{} % workaround to get line break after paragraph

Bryant~\cite{BRYANT86, BRYANT92} described three transformation rules to reduce
a graph such that it still represents the same function as before.

For each constant function, there exists only a single terminal node representing
it, e.g. for Boolean functions, only two terminal nodes exist, representing
\textbf{0} and \textbf{1}, respectively. Hence, when transforming a given BDD,
eliminate all but one terminal node for each constant function and redirect all
edges accordingly, i.e. to the one remaining node for each constant function.

There may be duplicate nonterminal nodes present in a given BDD. Formally, a node
$d$ is a duplicate if $var(d) = var(n) \land lo(d) = lo(n) \land hi(d) = hi(n)$
holds for any other node $n$. If this is the case, $d$ can be eliminated and all
edges are redirected to $n$.

The third and last transformation rule deals with completely redundant nonterminal
nodes. Intuitively, this rule should be straightforward: any node having the same
child on all outgoing edges is redundant because the actual value of the variable
does not change the result of the function. More formally, a nonterminal node $n$
is redundant if and only if $lo(n) = hi(n)$. Then, all incoming edges of $n$ can
be redirected to $lo(n)$ and $n$ can be deleted afterwards.

\begin{figure}[ht]
    \centering
    \subfigure[]{
        \includestandalone[height = 3cm]{figs/redundant-nonterminals-before}
        \label{subfig:redundant-nonterminals-before}
    }
    \hskip1cm
    \subfigure[]{
        \includestandalone[height = 3cm]{figs/redundant-nonterminals-after}
        \label{subfig:redundant-nonterminals-after}
    }
    \caption{Eliminating redundant nonterminal nodes.}
    \label{fig:redundant-nonterminals}
\end{figure}

Figure~\ref{fig:bdd-and-obdd} shows the result, \ref{subfig:obdd}, of applying
the first two transformation rules to the BDD shown in \ref{subfig:bdd}.
The third rule is shown in Figure~\ref{fig:redundant-nonterminals}:
\ref{subfig:redundant-nonterminals-before} shows a BDD with redundant
nonterminal nodes (both B's, in essence) and
\ref{subfig:redundant-nonterminals-after} shows the equivalent OBDD without
redundant nonterminals.

Bryant already formally described an algorithm to transform an arbitrary graph
into a reduced one~\cite[p. 683]{BRYANT86}. 

OBDDs have one big advantage over other representations: their representation is
\textit{canonical}. As a consequence, important tests can be performed on an OBDD
in constant time, i.e. satisfiability and tautology tests. Moreover, OBDDs enable
other tests, such as variable independence and functional equivalence tests, to
be performed efficiently. \tbr

\section{Operations}
\label{sec:operations}

Bryant's~\cite{BRYANT86, BRYANT92} main focus was to define algorithms performing
symbolic operations on graphs representing Boolean functions. The most basic
operation is \textit{Apply} which applys a given operation $op$, e.g. \texttt{AND},
to two given functions $f_1$ and $f_2$, and returns the result of $f_1\;op\;f_2$.
Another operation is \textit{Restrict}, restricting a given variable $x$ to a
given (constant) value $c$, denoted $f|_{x\leftarrow c}$. Furthermore, the
operations \textit{Compose} and \textit{Satisfy} can be defined as graph
algorithms.

The following paragraphs summarize those operations and their properties briefly.
Implementation details are covered in Section~\ref{sec:implementational-aspects}.

\paragraph*{Restrict}
\mbox{} % workaround to get line break after paragraph

Although \textit{Apply} is the core operation, the \textit{Restrict} operation is
discussed first, mainly because it is used within \textit{Apply}. Besides,
\textit{Restrict} is straightforward and easy to understand.

A variable $x_i$, argument of a function $f$, can be restricted to a given value
$c$, denoted by $f|_{x_i\leftarrow c}$, as follows.

Starting from the root $n$ of the OBDD representation of $f$ and traversing the
OBDD depth-first, every node is checked for $var(n) = x_i$. This is done recursively
on the given graph, generating the resultant graph This node represents
the variable to be restricted. Now, there are two cases for $c$ to distinguish:
\begin{enumerate}
    \item{$c=0$: The incoming edge of $n$ is redirected to $lo(n)$.}
    \item{$c=1$: The incoming edge of $n$ is redirected to $hi(n)$.}
\end{enumerate}

By applying the three transformation rules of the reduction procedure in each
step, \textit{Restrict} generates a reduced graph immediately~\cite{BRYANT92}.

This procedure has linear time complexity in the number of nodes, i.e. $O(|V|)$,
assuming an efficient implementation (see
Section~\ref{sec:implementational-aspects} for details)~\cite{BRYANT92}. 
\tbr

\paragraph*{Apply}
\mbox{} % workaround to get line break after paragraph

Applies an operation $op$ to two given functions $f_1$ and $f_2$ and returns the
resulting function $f_1\;op\;f_2$. This is the most intuitive function one would
expect when dealing with Boolean functions and it has some interesting properties
too, i.e. the complement of $f_1$ can be computed by setting $f_2$ to \textbf{1}
and $op$ to $\oplus$ (\texttt{XOR}). Moreover, the already mentioned functional
equivalence can be tested by applying $\overline{\oplus}$ (\texttt{XNOR}) to
$f_1$ and $f_2$ for all relevant cases. Therefore, Bryant~\cite{BRYANT92} defined
a function $d(x_1, \ldots, x_n)$ for \textit{Don't cares}:

$d(x_1, \ldots, x_n)=
\begin{cases}
    1, & \text{if values are not relevant} \\
    0, & otherwise
\end{cases}
$

\noindent
Using this function, one check if $f_1$ and $f_2$ are functionally equivalent by
computing $(f_1\overline{\oplus}f_2)\lor d$. If the result is \textbf{1}, $f_1$
and $f_2$ are functionally equivalent.

\textit{Apply} traverses the given graph depth-first, creating the resultant OBDD
step by step. Starting from the roots $n_1$ and $n_2$, new nodes are created for
each branching point of the graphs of $f_1$ and $f_2$, respectively.

\textit{Shannon's expansion} forms the basis of the recursive
algorithm~\cite{BRYANT86}:
\begin{center}
$
f_1 op f_2 =
\overline{x_i} \land \left(f_1|_{x_i\leftarrow 0}\;op\;f_2|_{x_i\leftarrow 0}\right)
\lor x_i \land \left(f_1|_{x_i\leftarrow 1}\;op\;f_2|_{x_i\leftarrow 1}\right)
$
\end{center}

\noindent
The recursive procedure then has three different cases. Note that a node is only
created if no equivalent node is already present in the resultant graph.
\begin{enumerate}
    \item{
        If $n_1$ and $n_2$ are both terminal nodes, then a terminal node
        representing the value $value(n_1)\;op\;value(n_2)$ is added to the
        resultant graph and the recursion terminates.
    }
    \item{
        If either $n_1$ or $n_2$ is a nonterminal node, then:
        \begin{enumerate}
            \item{
                If $var(n_1) = var(n_2)$, a node having $var(n_1)$ is created and
                the procedure is applied recursively on $(lo(n_1), lo(n_2))$ and
                $(hi(n_1), hi(n_2))$.
            }
            \item{
                If $var(n_1)$ is a nonterminal and $n_2$ is eiter a terminal node
                or $var(n_1) < var(n_2)$, a node having $var(n_1)$ is created and
                the procedure is applied recursively on $(lo(n_1), n_2)$ and
                $(hi(n_1), n_2)$.
            }
        \end{enumerate}
    }
\end{enumerate}

To get a reduced graph immediately, the three transformation rules are utilized
again for each step~\cite{BRYANT92}.

There are some refinements when it comes to implementation. Those are covered in
Section~\ref{sec:implementational-aspects} as well as the original paper of
Bryant~\cite{BRYANT86, BRYANT92}.  However, assuming an efficient implementation,
the time complexity can be bound to
$O\left(|V_{f_1}| \cdot |V_{f_2}|\right)$~\cite{BRYANT86, BRYANT92}.

The full pseudocode defined by Bryant can be found in~\cite[p. 685]{BRYANT86}. \tbr

\paragraph*{Compose}
\mbox{} % workaround to get line break after paragraph

This operation is merely based upon calls to \textit{Apply} and \textit{Restrict}.
Utilizing \textit{Shannon's expansion}, Bryant~\cite{BRYANT86} formulated the
composition of two functions $f_1$ and $f_2$ as
\begin{center}
$
f_1|_{x_i=f_2}=
f_2 \land f_1|_{x_i=1} \lor \overline{f_2} \land f_1|_{x_i=0}
$
\end{center}

This would result in an algorithm having a worst-case time complexity of 
$O\left(|V_{f_1}|^2 \cdot |V_{f_2}|^2\right)$. Therefore, Bryant~\cite{BRYANT86}
already proposed to extend the \textit{Apply} operation to support ternary
operations and then use the equivalent \textit{if-then-else} ($ITE$)
representation:
\begin{center}
$
ITE\left(f_2, f_1|_{x_i=1}, f_1|_{x_i=0}\right) \equiv
f_2 \land f_1|_{x_i=1} \lor \overline{f_2} \land f_1|_{x_i=0}
$
\end{center}

\noindent
For a given node $x$, the $ITE$ operator for three nodes, \newline
$ITE(x, hi(x), lo(x))$, chooses $hi(x)$ if $x$ evaluates to true and $lo(x)$
otherwise. Computing $ITE(x, hi(x), lo(x))$ is accomplished by utilizing a
recursive formulation~\cite{BRACE90}. To shorten the recursive formula, $l$ and
$h$ are used to represent $lo(x)$ and $hi(x)$, respectively.
\begin{center}
$
ITE(x, h, l) =
(var(x), ITE(x|_{x=1}, h|_{x=1}, l|_{x=1}), ITE(x|_{x=0}, h|_{x=0}, l|_{x=0}))
$
\end{center}

This formulation is based upon the fact, that every node $n$ of an OBDD represents
a Boolean function and is denoted by a triple $(var(n), hi(n), lo(n))$. Brace et
al.~\cite{BRACE90} called the variable associated with $n$, i.e. $x_n$ the
\textit{top variable} of $n$.

The time complexity then improves to be
$O\left(|V_{f_1}|^2 \cdot |V_{f_2}|\right)$~\cite{BRYANT86} when using the $ITE$
operator.~\cite[p. 686]{BRYANT86} lists Bryant's full pseudocode.

Bryant~\cite{BRYANT86} also described another, even more efficient way to compose
two function graphs. But this approach only applicable under restricted conditions.
\tbr

\paragraph*{Satisfy}
\mbox{} % workaround to get line break after paragraph

In essence, Bryant~\cite{BRYANT86} described two operations, i.e.
\textit{Satisfy-one} and \textit{Satisfy-all}, both concerned with the satisfying
set. As the name suggests, \textit{Satisfy-one} selects a single element and
\textit{Satisfy-all} selects all elements from the satisfying set.

\textit{Satisfy-one} traverses the OBDD depth-first and uses backtracking until
a terminal node of the constant function \textbf{1} is encountered. If such a
node is found, the corresponding Boolean function is satisfiable and true is
returned. Furthermore, an array representing the satisfying variable assignment
is assigned. The time complexity for a reduced graph is linear, i.e.
$O(|V_f|)$~\cite{BRYANT86}.

\textit{Satisfy-all} also traverses the OBDD depth-first. Every time the terminal
node having value \textbf{1} is traversed, it is printed. The recursive procedure
terminates as soon as the terminal node having value \textbf{0} is reached. This
results in a time complexity of $O(|V_f| \cdot |S_f|)$, whereas $S_f$ denotes the
satisfying set~\cite{BRYANT86}. \tbr

\section{Implementational Aspects}
\label{sec:implementational-aspects}

Bryant~\cite{BRYANT86} already observed the importance of utilizing efficient
techniques to implement the operations. Computation applied to OBDDs has a highly
dynamic character without specific memory access patterns~\cite{BRYANT92}.

Hence, the following sections cover important aspects to keep in mind when
implementing an OBDD framework efficiently, i.e. efficient data structures, the
$ITE$ operator, how to possibly approach the variable ordering problem and
\textit{garbage collection}. \tbr

\subsection{Efficient Data Structures}
\label{subsec:efficient-data-structures}

\paragraph*{Hash Tables}
\mbox{} % workaround to get line break after paragraph

Hash tables maintain \textit{key}-\textit{value}-pairs, returning the associated
value for a given key in (amortized) constant time. Collisions, i.e. equivalent
value for different keys, are resolved by chaining all associated values in a 
linked list~\cite{BRACE90}.

This is especially useful to refine \textit{Apply} in order to guarantee the time
complexity of $O\left(|V_{f_1}| \cdot |V_{f_2}|\right)$. Using a hash table to
match pairs of nodes ($n_1$, $n_2$) to a single node $m$, \textit{Apply} avoids
making multiple recursive calls to equivalent pairs of nodes and thus avoids
computing equivalent subgraphs multiple times. Therefore, before computing a
subgraph, \textit{Apply} checks whether an entry is present for the given pair
of nodes. If so, the associated value $m$ is used instead of computing the
subgraph~\cite{BRYANT86, BRYANT92}.

Moreover, hash tables are useful to generate a reduced graph directly from some
operations by maintaing a hash table associating triples
($var(n)$, $lo(n)$, $hi(n)$) with a single nonterminal node $n$. This is done for
each nonterminal node $n$ generated while executing the
operation~\cite{BRYANT92}. This is also referred to as
\textit{unique-table}~\cite{BRACE90} imposes the canonical form of an OBDD. If a
new node is generated, a corresponding entry is created in the unique-table.

There exists a special version of hash tables, so-called
\textit{hash-based caches}, which do not resolve collisions, i.e. overwrite
existing entries, and issue a cache miss if a looked up element is not found.
As will be seen, \textit{Hash-based caches} are useful to provide an efficient
implementation of the $ITE$ operator. \tbr

\paragraph*{Graph Representation}
\mbox{} % workaround to get line break after paragraph

To reduce the number of nodes of an OBDD, one can use \textit{complement edges}.
A complement edge is an edge holding a single bit to indicate complementation.
Hence, when $\overline{f}$ needs to be represented and a node $f$ is already
present, a complement edge can be used to connect $f$ and thus avoid
constructing the intermediate node $\overline{f}$. Also one of the two terminal
nodes (e.g. \textbf{1}) can be removed by just using a complement edge to connect
the other one (e.g. \textbf{0})~\cite{BRACE90}.

Brace et al.~\cite{BRACE90} identified four functionally equivalent pairs of
functions to be used for complement edges in order to maintain the canonical form.
Let $x$ be the node having $lo(x)$ and $hi(x)$ on its outgoing 0- and 1-edge,
respectively. Moreover, let $in(x)$ be the (one) incoming edge of node $x$ and
$\overline{c}$ the complement of $c$. Then, the following table sums up the
four pairs identified by Brace et al.~\cite{BRACE90}.

\begin{center}
    \begin{tabular}{lll}
        $\left(in(x), lo(x), hi(x)\right)$ & $\Leftrightarrow$ & $\left(\overline{in(x)}, \overline{lo(x)}, \overline{hi(x)}\right)$ \tabularnewline
        $\left(\overline{in(x)}, lo(x), hi(x)\right)$ & $\Leftrightarrow$ & $\left(in(x), \overline{lo(x)}, \overline{hi(x)}\right)$ \tabularnewline
        $\left(in(x), \overline{lo(x)}, hi(x)\right)$ & $\Leftrightarrow$ & $\left(\overline{in(x)}, lo(x), \overline{hi(x)}\right)$ \tabularnewline
        $\left(\overline{in(x)}, \overline{lo(x)}, hi(x)\right)$ & $\Leftrightarrow$ & $\left(in(x), lo(x), \overline{hi(x)}\right)$ \tabularnewline
    \end{tabular}
\end{center}

Also, the 1-edge of each node must always be a regular one to guarantee a
canonical form.

Implementing complement edges enables one to compute the complement and identify
complement functions in constant time (because $f$ and $\overline{f}$ use the same
node). According to Brace et al.~\cite{BRACE90} this reduces the total runtime
to form the OBBDD by almost a factor of 2 (for 12 examples).

Another refinement to the graph representation, also proposed by Brace et
al.~\cite{BRACE90}, is to integrate the unique-table into the graph representation,
i.e. linking the collision chain of each node to the corresponding unique-table
entry, to improve memory usage. \tbr

\subsection{ITE Operator}
\label{subsec:ite-operator}

Accoring to Brace et al.~\cite{BRACE90}, the $ITE$ operator forms the core of an
efficient OBDD package implementation. Hence, they used a hash-based cache, called
\textit{caching computed-table}, to implement it, exploiting a high locality of
reference and consuming less memory.

Compared to using a normal hash table, this results in more recursive calls to 
$ITE$ (because of cache misses) but less time spent in garbage collection
(described in Section~\ref{subsec:garbage-collection}) and look-ups (because no
collision chains need to be searched).

Nevertheless, it is worth noting that the worst-case time complexity increases
to be exponential if all keys are hashed to the same value, compared to a
polynomial time complexity for normal hash tables~\cite{BRACE90}. 

Furthermore, Brace et al.~\cite{BRACE90} advise to use \textit{standard triples},
i.e. to define an $ITE(f_1, f_2, f_3)$-based equivalence relation on sets of
three functions $f_1$, $f_2$ and $f_3$. This takes advantage of the fact that
different parameters may yield the same result when $ITE$ is called. Hence, before
the computed-table is accessed when executing $ITE$, the arguments are replaced
by the standard arguments. Using this approach some recomputations can be avoided
and, obviously, less space is consumed by the computed-table~\cite{BRACE90}.

Brace et al.~\cite[p. 42]{BRACE90} provides the pseudocode of the $ITE$ algorithm
as well as a modification, called $ite\_constant$, which can be used to implement
logical implication tests more efficiently by avoiding the construction of
intermediate nodes. \tbr

\subsection{Dynamic Variable Ordering}
\label{subsec:dynamic-variable-ordering}

For an OBDD package it is desirable to provide the possibility to automatically 
choose a good, though not optimal variable order for arbitrary functions. Of
course, there exist heuristics to order variables before processing but
Rudell~\cite{RUDELL93} proposed to integrate the determination and maintainance
of the variable order into the OBDD package itself. This approach to the variable
ordering problem is called \textit{dynamic variable ordering} and increases the
robustness of an OBDD package by removing the necessity of choosing a proper
variable ordering beforehand and thus running the risk of spacing out.

Dynamic variable ordering executes the \textit{sifting} algorithm, also proposed
by Rudell~\cite{RUDELL93}, to reorder the variables periodically and so minimize
the size of the OBDD. This on-the-fly approach enabled Rudell~\cite{RUDELL93} to
overcome hard problems for which heuristics did not find a variable ordering good
enough to actually solve them, i.e. heuristics were able to solve 24 out of 35
large circuits from the IWLS'91 and dynamic variable ordering using the sift
algorithm was able to solve 33 out of these 35 large circuits~\cite{RUDELL93}.

Periodically means, that a reordering is not performed by user requests but at
appropriate points, determined by the OBDD package itself and so eliminate any
user responsibility.

The core forms an efficient variable swap implementation, i.e. keep the changes
in the OBDD as local as possible when swapping two adjacent variables $x$ and
$y$. It has been found that swapping variable of two adjacent levels $i$ and
$(i+1)$ only affects the nodes of these two levels. Hence, Rudell~\cite{RUDELL93}
proposed to keep a separate unique-table for each level of the OBDD, similar to
the last refinement in \textit{Graph representation} of
Section~\ref{subsec:efficient-data-structures}. In essence, keeping separate 
unique-tables for each node is the best solution.

To ensure that each node represents the same function before and after the variable
swap, Rudell~\cite{RUDELL93} proposed a node overwriting strategy. A given node
$(var(x_i), hi(x_i), lo(x_i))$ at level $i$ is overwritten by the triple
\begin{center}
$(var(x_{i+1}), (x_i, h|_{x=1}, l|_{x=1}), (x_i, h|_{x=0}, l|_{x=0}))$
\end{center}
Here the notation of \textit{Compose} (Section~\ref{sec:operations}) is reused
to simplify the formula, i.e. $h$ ($l$) denotes $hi(x_i)$ ($lo(x_i)$).

Rudell~\cite{RUDELL93} also proposed to clear the computed-table and issue a
garbage collection before minimizing the OBDD. Afterwards, all nodes of level
$(i+1)$ can be freed incrementally if there exist no references from elsewhere than
level $i$.

Unfortunately, dynamic variable ordering has some bad consequences as well, namely
\textit{negate-input-} and \textit{negate-else-edges} cannot be used without
loosing the (desired) local complexity of variable swapping.

\begin{figure}[ht]
    \centering
    \includestandalone[height = 3cm]{figs/min-obdd}
    \label{fig:min-obdd}
    \caption{Minimized OBDD (optimal).}
\end{figure}
\tbr

\subsection{Garbage Collection}
\label{subsec:garbage-collection}

\tbd

\section{Limitations}
\label{sec:limitations}

\tbd

\section{Alternative Representations}
\label{sec:alternative-representations}

\tbd

% balance columns on last page
\balance

\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}
